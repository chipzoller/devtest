---
title: "VMworld 2017, Conclusion and Final Thoughts"
date: 2017-09-11
description: "Conclusion and final thoughts wrapping up VMworld 2017."
# author: "John Doe"
draft: false
menu: main
# featureImage: "/images/path/file.jpg"
categories:
  - Technology
tags:
  - vmworld
---

I wrote last about the first two days of VMworld 2017 and then nothing else. There’s a good reason for that since day three contained no general sessions. Day four consisted of three different speakers from areas such as bionics, AI, and medical technology presenting their latest research and giving an effective overview of the industry framed inside human conditions of various aspects. VMware calls this “day five” and you can read the rundown of the happenings on their blog [here](https://blogs.vmware.com/vmworld/2017/08/vmworld-2017-us-recap-day-five.html). A couple things I’d like to do in this article are to present possible lessons learned from these engaging speakers and liken them to present-day concepts within the field of information technology, although not virtualization necessarily, and data management in general. I want to follow up with a section that attempts to tie it all up in a neat bundle and provide some interpretation on the announcements.

The first speaker, MIT’s Hugh Herr, whom audiences immediately noted was a double amputee, spoke of how his research is advancing the field of bionics. Specifically, how artificial limbs are being interfaced with the human body via nerve impulse sensors and advanced surgical techniques. In his presentation, he demonstrated how new amputation methods that preserve certain muscle structures can be used to create a bioelectrical interface to an electromechanical leg that can be controlled by the wearer’s brain. In this way, the replacement limb becomes a part of that person that can be felt and controlled and not merely retrofitted onto the body. The parallel that immediately came to mind was the movement of Internet of Things. In the recent IoT trend, we are replacing our edges, our peripheral equipment, and our everyday devices with intelligent ones capable of providing telemetry and feedback that was never before possible. Refrigerators that before knew only a binary state of “cooling” or “not cooling” are able to inform us of so much more. Our homes are capable of providing feedback if an intruder comes calling, or are able to turn on and off devices at a whim. And our cars, which are pilotable vehicles but are effectively an extension of ourselves, are becoming self-aware and capable of driving without any human intervention. Indeed, we are gradually replacing those limbs with ones that can see and feel and report new types of data that inform us of our surrounding physical world, thereby increasing bodily cognition. VMware is actively [exploring this field](https://www.vmware.com/solutions/iot.html), and one of the solutions they are bringing to market is called [Pulse](https://www.vmware.com/products/pulse.html). The first product in this new category is Pulse IoT Center, an enterprise-grade management and monitoring station for IoT devices. Much is happening in this space, so very interesting to see where this goes.

The second speaker was Rana el Kaliouby of the MIT Media Lab who spoke and presented a new product designed to humanize technology through emotion AI. In her research, she asks the question, “what would happen if technology could identify emotions as other humans can?” During her presentation, she demonstrated how her product, Affectiva, can identify facial responses of the human viewer and then dynamically change that content based on those reactions. Imagine digital advertising in a world where the viewer’s facial responses indicating their emotional state can influence the type of content shown to that viewer, personalized on a person-to-person basis. A compelling demonstration during this talk was a set of smart glasses designed for autistic patients that could sense the emotional state of the subject in front and communicate that to the wearer with simple traffic light colors. (Patients with severe autism often have difficulties in interpreting and responding to human facial nuances that may indicate emotional state.)

The third and final speaker was Dr. Peter Weinsock of Boston Children’s Hospital who spoke of rehearsal in the medical industry. Dr. Weinsock, an anesthesiologist, spoke of the problem in today’s hospitals where critical, complicated surgeries—especially those infrequently conducted due to the specialized nature or rarity—are not rehearsed prior to being performed. He went on to say further that mistakes in the operating room often don’t occur because doctors aren’t familiar with the procedures, but because teams don’t come together. In order to address this, he is helping to develop surgical simulators whereby life-like patient replicas can be created and life-saving surgeries practiced by teams of doctors before they ever walk into the emergency room. Similar to how a sports team might prepare, they discuss the procedure, practice it as a team, and discuss the results and review feedback. During his talk, one example provided consisted of a patient diagnosed with hydrocephalus, a medical condition in which cerebrospinal fluid builds up in the brain causing it to swell and deform the cranium. Doctors at Boston Children’s, through use of this medical simulator technology, were able to create a 3D-printed replica of the patient’s head upon receiving MRI and CT scans, designed a surgery to remodel the skull alongside a plastic surgeon, and carried out that surgery during simulations before ever requesting the child visit the hospital. Ultimately, the surgery was a success, and no doubt this breakthrough technology will help to improve quality of care resulting in saving more lives and delivering better quality of life to patients. The parallel drawn here is the need for the same sort of rehearsal when it comes to disaster recovery. Very often today, enterprises design (and some even do not) DR plans and implement some solution to cover them, but never actually test or rehearse the procedure. When true disaster strikes, it then becomes a guessing game as to if the business can recover. Never a good thing to do, as I’m sure you will agree. As enterprises in today’s market necessitate and demand an always-on datacenter, it is imperative that they implement the correct set of products to achieve DR, but that they rehearse and refine those procedures regularly. Only through scheduled rehearsal and review of DR plans can businesses truly be prepared for when disaster strikes. Having confidence that one can recover and get back online is paramount to successful operations.

VMworld 2017 was filled with a number of great product announcements, exciting sessions, and big implications for what the future vision of technology looks like on the horizon ahead. We saw a lot of buzz around the new VMware Cloud on AWS solution, which is already exciting many customers, and we saw and heard new developments in both the container and IoT space. Both cloud, especially through hybrid cloud, and containers or IoT will be huge initiatives for companies in the next few years, and it sounds like VMware is strongly focused in bringing products and services to market that cater to these needs. Lastly, we heard some inspiring speakers present research and technology that will have impact on human life in the near and, likely, far future. Investigate some of these announcements for yourself using these articles as your guide. Many of the sessions at VMworld have been recorded and will be making their way online soon. Likewise, many of the new hands-on-labs which involve many of these technologies will be posted to the HOL site in the coming weeks and months. I’d strongly recommended you use this time to become up-to-speed on these innovations to help lead your company on its way through their digital transformation journey. See you all next year back in Las Vegas for VMworld 2018!
